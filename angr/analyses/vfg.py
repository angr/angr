from collections import defaultdict
import logging

import networkx

import simuvex
import claripy
import angr
import archinfo

from ..entry_wrapper import SimRunKey, FunctionKey, EntryWrapper
from ..analysis import Analysis, register_analysis
from ..errors import AngrVFGError, AngrError, AngrVFGRestartAnalysisNotice, AngrJobMergingFailureNotice
from .forward_analysis import ForwardAnalysis, AngrSkipEntryNotice
from .cfg_utils import CFGUtils

l = logging.getLogger(name="angr.analyses.vfg")

# The maximum tracing times of a basic block before we widen the results
MAX_ANALYSIS_TIMES_WITHOUT_MERGING = 5
MAX_ANALYSIS_TIMES = 80

class VFGJob(EntryWrapper):
    """
    An EntryWrapper that contains vfg local variables
    """
    def __init__(self, *args, **kwargs):
        super(VFGJob, self).__init__(*args, **kwargs)

        self.call_stack_suffix = None
        self.simrun = None
        self.vfg_node = None
        self.is_call_jump = None
        self.call_target = None
        self.dbg_exit_status = {}
        self.is_return_jump = None

        # if this job has a call successor, do we plan to skip the call successor or not
        self.call_skipped = False
        # if the call is skipped, calling stack of the skipped function is saved in `call_context_key`
        self.call_function_key = None  # type: FunctionKey

        self.call_task = None  # type: CallAnalysis

    @property
    def state(self):
        return self.path.state

    @state.setter
    def state(self, state):
        self.path.state = state

    @property
    def simrun_key(self):
        return self._simrun_key


class AnalysisTask(object):
    """
    An analysis task describes a task that should be done before popping this task out of the task stack and discard it.
    """
    def __init__(self):
        pass

    @property
    def done(self):
        raise NotImplementedError()

class FunctionAnalysis(AnalysisTask):
    """
    Analyze a function, generate fix-point states from all endpoints of that function, and then merge them to one state.
    """
    def __init__(self, function_address, return_address):
        super(FunctionAnalysis, self).__init__()

        self.function_address = function_address
        self.return_address = return_address

        self.call_analysis = None

        # tracks all jobs that are live currently
        self.jobs = [ ]

    def __repr__(self):
        s = "<Function @ %#08x with %d jobs>" % (self.function_address, len(self.jobs))
        return s

    #
    # Properties
    #

    @property
    def done(self):
        return not self.jobs

class CallAnalysis(AnalysisTask):
    """
    Analyze a call by analyze all functions this call might be calling, collect all final states generated by analyzing
    those functions, and merge them into one state.
    """
    def __init__(self, address, return_address, function_analysis_tasks=None):
        super(CallAnalysis, self).__init__()

        self.address = address
        self.return_address = return_address
        self.function_analysis_tasks = function_analysis_tasks if function_analysis_tasks is not None else [ ]

        self._final_jobs = [ ]

    def __repr__(self):
        s = "<Call @ %#08x with %d function tasks>" % (self.address, len(self.function_analysis_tasks))
        return s

    #
    # Properties
    #

    @property
    def done(self):
        for task in self.function_analysis_tasks:
            if not task.done:
                return False
        return True

    #
    # Public methods
    #

    def register_function_analysis(self, task):

        assert isinstance(task, FunctionAnalysis)

        self.function_analysis_tasks.append(task)
        task.call_analysis = self

    def add_final_job(self, job):

        self._final_jobs.append(job)

    def merge_jobs(self):

        assert self._final_jobs

        job = self._final_jobs[0]

        for other in self._final_jobs[1:]:
            job.state = job.state.merge(other.state)[0]

        return job

class VFGNode(object):
    """
    A descriptor of nodes in a Value-Flow Graph
    """
    def __init__(self, addr, key, state=None):
        """
        Constructor.

        :param int addr:
        :param SimRunKey key:
        :param simuvex.SimState state:
        """
        self.key = key
        self.addr = addr
        self.state = None
        self.widened_state = None
        self.narrowing_times = 0
        self.all_states  = [ ]
        self.events = [ ]
        self.input_variables = [ ]
        self.actions = [ ]
        self.final_states = [ ]

        if state:
            self.all_states.append(state)
            self.state = state

    def __hash__(self):
        return hash(self.key)

    def __eq__(self, o):
        return (type(self) == type(o) and # pylint:disable=unidiomatic-typecheck
               self.key == o.key and self.addr == o.addr and
               self.state == o.state and self.actions == o.actions and
               self.events == o.events and self.narrowing_times == o.narrowing_times and
               self.all_states == o.all_states and self.widened_state == o.widened_state and
               self.input_variables == o.input_variables)

    def __repr__(self):
        s = "VFGNode[%#x] <%s>" % (self.addr, repr(self.key))
        return s

    def append_state(self, s, is_widened_state=False):
        """
        Appended a new state to this VFGNode.
        :param s: The new state to append
        :param is_widened_state: Whether it is a widened state or not.
        """

        if not is_widened_state:
            self.all_states.append(s)
            self.state = s

        else:
            self.widened_state = s


class VFG(ForwardAnalysis, Analysis):   # pylint:disable=abstract-method
    """
    This class represents a control-flow graph with static analysis result.

    Perform abstract interpretation analysis starting from the given function address. The output is an invariant at
    the beginning (or the end) of each basic block.

    Steps:
    # Generate a CFG first if CFG is not provided.
    # Identify all merge points (denote the set of merge points as Pw) in the CFG.
    # Cut those loop back edges (can be derived from Pw) so that we gain an acyclic CFG.
    # Identify all variables that are 1) from memory loading 2) from initial values, or 3) phi functions. Denote
        the set of those variables as S_{var}.
    # Start real AI analysis and try to compute a fix point of each merge point. Perform widening/narrowing only on
        variables \\in S_{var}.
    """

    # TODO: right now the graph traversal method is not optimal. A new solution is needed to minimize the iteration we
    # TODO: access each node in the graph

    def __init__(self,
                 cfg=None,
                 context_sensitivity_level=2,
                 function_start=None,
                 interfunction_level=0,
                 initial_state=None,
                 avoid_runs=None,
                 remove_options=None,
                 timeout=None,
                 start_at_function=True,
                 ara=None,
                 ):
        """
        :param project: The project object.
        :param context_sensitivity_level: The level of context-sensitivity of this VFG.
                                        It ranges from 0 to infinity. Default 2.
        :param function_start: The address of the function to analyze. N
        :param interfunction_level: The level of interfunction-ness to be
        :param initial_state: A state to use as the initial one
        :param avoid_runs: A list of runs to avoid
        :param remove_options: State options to remove from the initial state. It only works when `initial_state` is
                                None
        :param int timeout:
        :param bool start_at_function:
        """

        ForwardAnalysis.__init__(self, order_entries=True, allow_merging=True)

        # Related CFG.
        # We can still perform analysis if you don't specify a CFG. But providing a CFG may give you better result.
        self._cfg = cfg

        # Where to start the analysis
        self._start = function_start if function_start is not None else self.project.entry

        # Other parameters
        self._avoid_runs = [ ] if avoid_runs is None else avoid_runs
        self._context_sensitivity_level = context_sensitivity_level
        self._interfunction_level = interfunction_level
        self._state_options_to_remove = set() if remove_options is None else remove_options
        self._timeout = timeout
        self._start_at_function = start_at_function

        self._initial_state = initial_state

        self._ara = ara

        self._nodes = {}            # all the vfg nodes, keyed on simrun keys
        self._normal_states = { }   # Last available state for each program point without widening
        self._widened_states = { }  # States on which widening has occurred

        # Initial states of each function, which is context sensitive
        # It maps function key to its states
        self._function_initial_states = defaultdict(dict)
        # Final states of each function, right after `ret` is called. Also context sensitive.
        # even if a function may have multiple return sites, as long as they all return to the same place, there is
        # only one final state of that function.
        self._function_final_states = defaultdict(dict)

        # All final states are put in this list
        self.final_states = [ ]

        self._state_initialization_map = defaultdict(list)

        self._exit_targets = defaultdict(list) # A dict to log edges and the jumpkind between each basic block
        # A dict to record all blocks that returns to a specific address
        self._return_target_sources = defaultdict(list)

        self._pending_returns = {}

        self._thumb_addrs = set()   # set of all addresses that are code in thumb mode

        self._final_address = None  # Address of the very last instruction. The analysis is terminated there.

        self._function_merge_points = {}

        self._task_stack = [ ]

        self._tracing_times = defaultdict(int)

        # counters for debugging
        self._execution_counter = defaultdict(int)

        # Start analysis
        self._analyze()

    #
    # Internal properties
    #

    @property
    def _current_function_address(self):
        return self._task_stack[-1].function_address

    @property
    def _top_task(self):
        """
        Get the first task in the stack.

        :return: The top task in the stack, or None if the stack is empty.
        :rtype: AnalysisTask
        """

        if not self._task_stack:
            return None
        return self._task_stack[-1]

    @property
    def function_initial_states(self):
        return self._function_initial_states

    @property
    def function_final_states(self):
        return self._function_final_states

    #
    # Public methods
    #

    def get_any_node(self, addr):
        """
        Get any VFG node corresponding to the basic block at @addr.
        Note that depending on the context sensitivity level, there might be
        multiple nodes corresponding to different contexts. This function will
        return the first one it encounters, which might not be what you want.
        """
        for n in self.graph.nodes():
            if n.addr == addr:
                return n

    def irsb_from_node(self, node):
        return self.project.factory.sim_run(node.state, addr=node.addr, num_inst=len(node.instruction_addrs))

    def get_paths(self, begin, end):
        """
        Get all the simple paths between @begin and @end.
        Returns: a list of angr.Path instances.
        """
        paths = self._get_nx_paths(begin, end)
        a_paths = []
        for p in paths:
            runs = map(self.irsb_from_node, p)
            a_paths.append(angr.path.make_path(self.project, runs))
        return a_paths

    #
    # Operations
    #

    def copy(self):
        new_vfg = VFG(self.project)
        new_vfg._cfg = self._cfg
        new_vfg._graph = networkx.DiGraph(self.graph)
        new_vfg._nodes = self._nodes.copy()
        new_vfg._exit_targets = defaultdict(list, self._exit_targets)
        return new_vfg

    # Pickling helpers
    def __setstate__(self, s):
        self.__dict__.update(s)

    def __getstate__(self):
        return dict(self.__dict__)

    #
    # Main analysis routines, mostly overriding methods of ForwardAnalysis
    #

    def _pre_analysis(self):
        """
        Executed before analysis starts. Necessary initializations are performed here.

        :return: None
        """

        l.debug("Starting from %#x", self._start)

        # initialize the task stack
        self._task_stack = [ ]

        # initialize the execution counter dict
        self._execution_counter = defaultdict(int)

        # Generate a CFG if no CFG is provided
        if not self._cfg:
            l.debug("Generating a CFG, since none was given...")
            # TODO: can we use a fast CFG instead? note that fast CFG does not care of context sensitivity at all, but
            # TODO: for state merging, we also don't really care about context sensitivity.
            self._cfg = self.project.analyses.CFGAccurate(context_sensitivity_level=self._context_sensitivity_level,
                starts=(self._start,)
            )

        if not self._cfg.normalized:
            l.warning("The given CFG is not normalized, which might impact the performance/accuracy of the VFG "
                      "analysis.")

        # Prepare the state
        initial_state = self._prepare_initial_state(self._start, self._initial_state)
        initial_state.ip = self._start

        initial_state = self.project.arch.prepare_state(initial_state,
                                                        {'current_function': self._start, }
                                                        )

        # clear function merge points cache
        self._function_merge_points = {}

        # Create the initial path
        entry_state = initial_state.copy()
        entry_path = self.project.factory.path(entry_state)

        if self._start_at_function:
            # set the return address to an address so we can catch it and terminate the VSA analysis
            # TODO: Properly pick an address that will not conflict with any existing code and data in the program
            self._final_address = 0x4fff0000
            self._set_return_address(entry_state, self._final_address)

        job = VFGJob(entry_path.addr, entry_path, self._context_sensitivity_level,
                     jumpkind='Ijk_Boring', final_return_address=self._final_address,
                     )
        simrun_key = SimRunKey.new(entry_path.addr, job.get_call_stack_suffix(), job.jumpkind)
        job._simrun_key = simrun_key

        self._insert_entry(job)

        # create the task
        function_analysis_task = FunctionAnalysis(self._start, self._final_address)
        function_analysis_task.jobs.append(job)
        self._task_stack.append(function_analysis_task)

    def _entry_sorting_key(self, job):
        """
        Get the sorting key of a VFGJob instance.

        :param VFGJob job: the VFGJob object.
        :return: An integer that determines the order of this job in the queue.
        :rtype: int
        """

        MAX_ENTRIES_PER_FUNCTION = 1000000

        function_pos = list(reversed(
            list(task.function_address for task in self._task_stack if isinstance(task, FunctionAnalysis))
            )).index(job.func_addr)

        if job.addr not in self._merge_points(job.func_addr):
            # put it in the front, but still obeying their order
            # TODO: this order should be solely based on their sorting order.
            block_in_function_pos = job.addr - job.func_addr

        else:
            block_in_function_pos = self._merge_points(job.func_addr).index(job.addr)

        return block_in_function_pos + MAX_ENTRIES_PER_FUNCTION * function_pos

        # return self._cfg.get_topological_order(self._cfg.get_node(job.simrun_key))

    def _entry_key(self, job):
        """
        Return the SimRun key of the job. Two or more jobs owning the same SimRun key will be merged together.

        :param VFGJob job: The VFGJob instance.
        :return: The SimRun key to the job
        :rtype: SimRunKey
        """

        return job.simrun_key

    def _pre_entry_handling(self, job):
        """
        Some code executed before actually processing the entry.

        :param VFGJob job: the VFGJob object.
        :return: None
        """

        # did we reach the final address?
        if self._final_address is not None and job.addr == self._final_address:
            # our analysis should be termianted here
            raise AngrSkipEntryNotice()

        l.debug("Handling VFGJob %s", job)

        if not self._top_task:
            l.debug("No more tasks available. Skip the entry.")
            raise AngrSkipEntryNotice()

        assert isinstance(self._top_task, FunctionAnalysis)

        if job not in self._top_task.jobs:
            l.debug("The job is not recorded. SKip the entry.")
            raise AngrSkipEntryNotice()

        # increment the execution counter
        self._execution_counter[job.addr] += 1

        self._top_task.jobs.remove(job)

        # set up some essential variables and parameters
        job.call_stack_suffix = job.get_call_stack_suffix()
        job.jumpkind = 'Ijk_Boring' if job.path.state.scratch.jumpkind is None else \
            job.path.state.scratch.jumpkind

        current_path = job.path
        src_simrun_key = job.src_simrun_key
        src_exit_stmt_idx = job.src_exit_stmt_idx

        addr = current_path.addr
        input_state = current_path.state
        simrun_key = SimRunKey.new(addr, job.call_stack_suffix, job.jumpkind)

        if self._tracing_times[simrun_key] > MAX_ANALYSIS_TIMES:
            raise AngrSkipEntryNotice()

        self._tracing_times[simrun_key] += 1

        if simrun_key not in self._nodes:
            vfg_node = VFGNode(addr, simrun_key, state=input_state)
            self._nodes[simrun_key] = vfg_node

        else:
            vfg_node = self._nodes[simrun_key]

        job.vfg_node = vfg_node
        # log the current state
        vfg_node.state = input_state

        current_path.state = input_state

        # Execute this basic block with input state, and get a new SimRun object
        # unused result var is `error_occured`
        job.simrun, _, restart_analysis = self._get_simrun(input_state, current_path, addr)

        if restart_analysis:
            # We should restart the analysis because of something must be changed in the very initial state
            raise AngrVFGRestartAnalysisNotice()

        if job.simrun is None:
            # Ouch, we cannot get the simrun for some reason
            # Skip this guy
            raise AngrSkipEntryNotice()

        self._graph_add_edge(src_simrun_key,
                             simrun_key,
                             jumpkind=job.jumpkind,
                             src_exit_stmt_idx=src_exit_stmt_idx)

    def _get_successors(self, entry):
        # Extract initial values
        current_path = entry.path
        addr = entry.addr

        # Obtain successors
        if addr not in self._avoid_runs:
            all_successors = entry.simrun.successors + entry.simrun.unconstrained_successors
        else:
            all_successors = []

        # save those states
        entry.vfg_node.final_states = all_successors[:]

        # Update thumb_addrs
        if isinstance(entry.simrun, simuvex.SimIRSB) and current_path.state.thumb:
            self._thumb_addrs.update(entry.simrun.imark_addrs())

        if len(all_successors) == 0:
            if isinstance(entry.simrun,
                          simuvex.procedures.SimProcedures["stubs"]["PathTerminator"]):
                # If there is no valid exit in this branch and it's not
                # intentional (e.g. caused by a SimProcedure that does not
                # do_return) , we should make it return to its callsite.
                # However, we don't want to use its state as it might be
                # corrupted. Just create a link in the exit_targets map.
                retn_target = entry.call_stack.current_return_target
                if retn_target is not None:
                    new_call_stack = entry.call_stack_copy()
                    exit_target_tpl = new_call_stack.stack_suffix(self._context_sensitivity_level) + (retn_target,)
                    self._exit_targets[entry.call_stack_suffix + (addr,)].append(
                        (exit_target_tpl, 'Ijk_Ret'))
            else:
                # This is intentional. We shall remove all the pending returns generated before along this path.
                self._remove_pending_return(entry, self._pending_returns)

        # If this is a call exit, we shouldn't put the default exit (which
        # is artificial) into the CFG. The exits will be Ijk_Call and
        # Ijk_FakeRet, and Ijk_Call always goes first
        entry.is_call_jump = any([self._is_call_jumpkind(i.scratch.jumpkind) for i in all_successors])
        call_targets = [i.se.exactly_int(i.ip) for i in all_successors if self._is_call_jumpkind(i.scratch.jumpkind)]
        entry.call_target = None if not call_targets else call_targets[0]

        entry.is_return_jump = len(all_successors) and all_successors[0].scratch.jumpkind == 'Ijk_Ret'

        if entry.is_call_jump:
            # create the call task

            # TODO: correctly fill the return address
            call_task = CallAnalysis(entry.addr, None, [ ])
            self._task_stack.append(call_task)

            entry.call_task = call_task

        return all_successors

    def _handle_successor(self, job, successor, all_successors):
        """
        Process each successor generated by the job, and return a new list of succeeding jobs.

        :param VFGJob job: The VFGJob instance.
        :param simuvex.SimState successor: The succeeding state.
        :param list all_successors:  A list of all successors.
        :return: A list of newly created jobs from the successor.
        :rtype: list
        """

        # Initialize parameters
        addr = job.path.addr
        jumpkind = successor.scratch.jumpkind

        #
        # Get instruction pointer
        #

        if job.is_return_jump:
            ret_target = job.call_stack.current_return_target
            if ret_target is None:
                # We have no where to go according to our call stack. However, the callstack might be corrupted
                l.debug("According to the call stack, we have nowhere to return to.")
                return [ ]

            successor.ip = ret_target

        # this try-except block is to handle cases where the instruction pointer is symbolic
        try:
            successor_addrs = successor.se.any_n_int(successor.ip, 2)
        except simuvex.SimValueError:
            # TODO: Should fall back to reading targets from CFG
            # It cannot be concretized currently. Maybe we could handle
            # it later, maybe it just cannot be concretized
            return

        if len(successor_addrs) > 1:
            # multiple concrete targets
            if job.is_return_jump:
                # It might be caused by state merging
                # We may retrieve the correct ip from call stack
                successor.ip = job.call_stack.current_return_target

            else:
                return self._handle_successor_multitargets(job, successor, all_successors)

        # Now there should be one single target for the successor
        successor_addr = successor.se.exactly_int(successor.ip)

        # Get the fake ret successor
        fakeret_successor = None
        if self._is_call_jumpkind(jumpkind):
            fakeret_successor = all_successors[-1]

            # If the function we're calling into doesn't return, we should discard it
            if self._cfg is not None:
                func = self.kb.functions.function(addr=job.call_target)
                if func is not None and func.returning is False and len(all_successors) == 2:
                    del all_successors[-1]
                    fakeret_successor = None

        # Create a new call stack for the successor
        # TODO: why are we creating a new callstack even when we're not doing a call?
        new_call_stack = self._create_callstack(job, successor_addr, jumpkind, job.is_call_jump, fakeret_successor)
        if new_call_stack is None:
            l.debug("Cannot create a new callstack for address %#x", successor_addr)
            return
        new_call_stack_suffix = new_call_stack.stack_suffix(self._context_sensitivity_level)

        if self._is_call_jumpkind(jumpkind):

            new_function_key = FunctionKey.new(successor_addr, new_call_stack_suffix)
            # Save the initial state for the function
            self._save_function_initial_state(new_function_key, successor_addr, successor.copy())

            # bail out if we hit the interfunction_level cap
            if len(job.call_stack) >= self._interfunction_level:
                l.debug('We are not tracing into a new function %#08x as we hit interfunction_level limit', successor_addr)

                # mark it as skipped
                job.dbg_exit_status[successor] = "Skipped"

                job.call_skipped = True
                job.call_function_key = new_function_key

                return [ ]

        # Generate the new SimRun key
        new_simrun_key = SimRunKey.new(successor_addr, new_call_stack_suffix, jumpkind)

        #
        # Generate new VFG jobs
        #

        if jumpkind == "Ijk_Ret":
            assert not job.is_call_jump

            # Record this return
            self._return_target_sources[successor_addr].append(job.call_stack_suffix + (addr,))

            # Check if this return is inside our pending returns list
            if new_simrun_key in self._pending_returns:
                del self._pending_returns[new_simrun_key]

        # Check if we have reached a fixpoint
        if new_simrun_key in self._nodes:
            last_state = self._nodes[new_simrun_key].state

            _, _, merged = last_state.merge(successor)

            if merged:
                l.debug("%s didn't reach a fix-point", new_simrun_key)
            else:
                l.debug("%s reaches a fix-point.", new_simrun_key)
                return [ ]

        new_jobs = self._create_new_jobs(job, successor, new_simrun_key, new_call_stack)

        return new_jobs

    def _handle_successor_multitargets(self, job, successor, all_successors):
        """
        Generate new jobs for all possible successor targets when there are more than one possible concrete value for
        successor.ip

        :param VFGJob job: The VFGJob instance.
        :param simuvex.SimState successor: The succeeding state.
        :param list all_successors: All succeeding states from the same VFGJob.
        :return: A list of new succeeding jobs
        :rtype: list
        """

        new_jobs = [ ]

        # Currently we assume a legit jumping target cannot have more than 256 concrete values
        # TODO: make it a setting on VFG
        MAX_NUMBER_OF_CONCRETE_VALUES = 256

        all_possible_ips = successor.se.any_n_int(successor.ip, MAX_NUMBER_OF_CONCRETE_VALUES + 1)

        if len(all_possible_ips) > MAX_NUMBER_OF_CONCRETE_VALUES:
            l.warning("IP can be concretized to more than %d values, which means it might be corrupted.",
                      MAX_NUMBER_OF_CONCRETE_VALUES)
            return [ ]

        # Call this function to generate a successor for each possible IP
        for ip in all_possible_ips:
            concrete_successor = successor.copy()
            concrete_successor.ip = ip

            concrete_jobs = self._handle_successor(job, concrete_successor, all_successors)

            if job.is_call_jump:  # TODO: take care of syscalls
                for new_job in concrete_jobs:
                    # TODO: correctly fill the return address. The return address can be found from the
                    # TODO: fakeret successor in the `successors` list
                    function_analysis_task = FunctionAnalysis(new_job.addr, None)
                    # log the new job
                    function_analysis_task.jobs.append(new_job)
                    # put it onto the stack
                    self._task_stack.append(function_analysis_task)
                    # log it in the call_task
                    job.call_task.register_function_analysis(function_analysis_task)

            new_jobs.extend(concrete_jobs)

        return new_jobs

    def _post_entry_handling(self, job, new_jobs, successors):  # pylint:disable=unused-argument

        # Debugging output
        if l.level == logging.DEBUG:
            self._post_entry_handling_dbg(job, successors)

        # pop all tasks if they are finished
        task = self._top_task

        if task is None:
            # the task stack is empty
            return

        if isinstance(task, CallAnalysis):
            # the call never returns
            l.debug('%s never returns.', task)
            self._task_stack.pop()

        else:
            if task.done:
                l.debug('%s is finished.', task)
                self._task_stack.pop()

                # the next guy *might be* a call analysis task
                task = self._top_task
                if isinstance(task, CallAnalysis):
                    if task.done:
                        # awesome!
                        # pop it from the task stack
                        self._task_stack.pop()

                        if task._final_jobs:
                            # merge all jobs, and create a new job
                            new_job = task.merge_jobs()

                            # insert the entry
                            self._insert_entry(new_job)

                            # register the job to the top task
                            self._top_task.jobs.append(new_job)

    def _intra_analysis(self):
        pass

    def _merge_entries(self, *entries):

        l.debug("Merging entries %s", entries)

        # there should not be more than two entries being merged at the same time
        assert len(entries) == 2

        if not self._merge_points(self._current_function_address):
            raise AngrJobMergingFailureNotice()

        addr = entries[0].path.addr

        if self.project.is_hooked(addr) and \
                self.project.hooked_by(addr) is simuvex.s_procedure.SimProcedureContinuation:
            raise AngrJobMergingFailureNotice()

        if entries[0].path.addr not in self._merge_points(self._current_function_address):
            # if it's not a valid merge point, we don't merge it right now
            raise AngrJobMergingFailureNotice()

        # update jobs
        for entry in entries:
            if entry in self._top_task.jobs:
                self._top_task.jobs.remove(entry)

        path_0 = entries[0].path
        path_1 = entries[1].path

        merged_state, _ = self._merge_states(path_0.state, path_1.state)

        path = self.project.factory.path(merged_state)

        new_job = VFGJob(entries[0].addr, path, self._context_sensitivity_level, jumpkind=entries[0].jumpkind,
                         simrun_key=entries[0].simrun_key, call_stack=entries[0].call_stack
                         )

        self._top_task.jobs.append(new_job)

        return new_job

    def _entry_list_empty(self):

        if self._pending_returns:
            # We don't have any paths remaining. Let's pop a previously-missing return to
            # process

            top_task = self._top_task  # type: FunctionAnalysis
            func_addr = top_task.function_address

            pending_ret_key = None
            for k in self._pending_returns.iterkeys():  # type: SimRunKey
                if k.func_addr == func_addr:
                    pending_ret_key = k
                    break

            if pending_ret_key is None:
                # TODO: rewind the stack, and pop the correct pending job out of the queue
                raise NotImplementedError('Task stack rewinding is not implemented yet.')

            state, call_stack = self._pending_returns.pop(pending_ret_key)
            addr = pending_ret_key.addr

            # Unlike CFG, we will still trace those blocks that have been traced before. In other words, we don't
            # remove fake returns even if they have been traced - otherwise we cannot come to a fixpoint.

            new_path = self.project.factory.path(state)
            simrun_key = SimRunKey.new(addr,
                                       call_stack.stack_suffix(self._context_sensitivity_level),
                                       'Ijk_Ret'
                                       )
            job = VFGJob(new_path.addr,
                         new_path,
                         self._context_sensitivity_level,
                         simrun_key=simrun_key,
                         jumpkind=new_path.state.scratch.jumpkind,
                         call_stack=call_stack,
                         )
            self._insert_entry(job)

            top_task.jobs.append(job)

            l.debug("Tracing a missing return %#08x, %s", addr, repr(pending_ret_key))

    def _post_analysis(self):
        pass

    def _handle_states_merging(self, node, addr, new_state, tracing_times):
        """
        Examine if we have reached to a fix point for the current node, and perform merging/widening if necessary.

        :param node: An instance of VFGNode.
        :param new_state: The new input state that we want to compare against.
        :returns: A bool value indicating whether we have reached fix point, and the merge state/original state if possible.
        """
        tracing_times[node] += 1

        tracing_count = tracing_times[node]

        l.debug("Analyzing %s for the %dth time", node, tracing_count)

        if tracing_count == 1:
            node.append_state(new_state)
            return False, new_state

        if tracing_count > MAX_ANALYSIS_TIMES:
            l.debug("%s has been analyzed too many times. Skip.", node)

            return False, None

        # Extract two states
        old_state = node.state

        # The widening flag
        widening_occurred = False

        # TODO: _widen_points doesn't exist anymore!
        if addr in set(dst.addr for (_, dst) in self._widen_points):
            # We reached a merge point

            if tracing_count >= MAX_ANALYSIS_TIMES_WITHOUT_MERGING:

                if node.widened_state is not None:
                    # We want to narrow the state
                    widened_state = node.widened_state
                    merged_state, narrowing_occurred = self._narrow_states(node, old_state, new_state, widened_state)
                    merging_occurred = narrowing_occurred

                else:
                    # We want to widen the state
                    # ... but, we should merge them first
                    merged_state, merging_occurred = self._merge_states(old_state, new_state)
                    # ... then widen it
                    merged_state, widening_occurred = self._widen_states(old_state, merged_state)

                    merging_occurred = widening_occurred

            else:
                # We want to merge them
                merged_state, merging_occurred = self._merge_states(old_state, new_state)

        else:
            # Not a merge point
            # Always merge the state with existing states
            merged_state, merging_occurred = self._merge_states(old_state, new_state)

        if widening_occurred:
            node.append_state(merged_state, is_widened_state=True)

        else:
            node.append_state(merged_state)

        if merging_occurred:
            l.debug("Merging/widening/narrowing occured for %s. Returning a new state.", node)

            return True, merged_state
        else:
            # if simuvex.s_options.WIDEN_ON_MERGE in merged_state.options:
            #    merged_state.options.remove(simuvex.s_options.WIDEN_ON_MERGE)
            l.debug("%s reached fixpoint.", node)

            return False, None

    #
    # State widening, merging, and narrowing
    #

    @staticmethod
    def _widen_states(old_state, new_state):
        """
        Perform widen operation on the given states, and return a new one.

        :param old_state:
        :param new_state:
        :returns: The widened state, and whether widening has occurred
        """

        # print old_state.dbg_print_stack()
        # print new_state.dbg_print_stack()

        l.debug('Widening state at IP %s', old_state.ip)

        widened_state, widening_occurred = old_state.widen(new_state)

        # print "Widened: "
        # print widened_state.dbg_print_stack()

        return widened_state, widening_occurred

    def _narrow_states(self, node, old_state, new_state, previously_widened_state):  # pylint:disable=unused-argument,no-self-use
        """
        Try to narrow the state!

        :param old_state:
        :param new_state:
        :param previously_widened_state:
        :returns: The narrowed state, and whether a narrowing has occurred
        """

        l.debug('Narrowing state at IP %s', previously_widened_state.ip)

        s = previously_widened_state.copy()

        narrowing_occurred = False

        # TODO: Finish the narrowing logic

        return s, narrowing_occurred

    @staticmethod
    def _merge_states(old_state, new_state):
        """
        Merge two given states, and return a new one.

        :param old_state:
        :param new_state:
        :returns: The merged state, and whether a merging has occurred
        """

        # print old_state.dbg_print_stack()
        # print new_state.dbg_print_stack()

        merged_state, _, merging_occurred = old_state.merge(new_state)

        # print "Merged: "
        # print merged_state.dbg_print_stack()

        return merged_state, merging_occurred


    #
    # Helper methods
    #

    def _prepare_initial_state(self, function_start, state):
        """
        Get the state to start the analysis for function.

        :param int function_start: Address of the function
        :param SimState state: The program state to base on.
        """

        if state is None:
            state = self.project.factory.blank_state(mode="static",
                                                     remove_options=self._state_options_to_remove
                                                     )

        # make room for arguments passed to the function
        sp = state.regs.sp
        sp_val = state.se.exactly_int(sp)
        state.memory.set_stack_address_mapping(sp_val,
                                               state.memory.stack_id(function_start) + '_pre',
                                               0
                                               )
        state.registers.store('sp', sp - 0x100)

        # Set the stack address mapping for the initial stack
        state.memory.set_stack_size(state.arch.stack_size)
        initial_sp = state.se.any_int(state.regs.sp) # FIXME: This is bad, as it may lose tracking of multiple sp values
        initial_sp -= state.arch.bytes
        state.memory.set_stack_address_mapping(initial_sp,
                                               state.memory.stack_id(function_start),
                                               function_start
                                               )

        return state

    def _set_return_address(self, state, ret_addr):
        """
        Set the return address of the current state to a specific address. We assume we are at the beginning of a
        function, or in other words, we are about to execute the very first instruction of the function.

        :param simuvex.SimState state: The program state
        :param int ret_addr: The return address
        :return: None
        """

        # TODO: the following code is totally untested other than X86 and AMD64. Don't freak out if you find bugs :)
        # TODO: Test it

        ret_bvv = state.se.BVV(ret_addr, self.project.arch.bits)

        if self.project.arch.name in ('X86', 'AMD64'):
            state.stack_push(ret_bvv)
        elif self.project.arch.name in ('ARMEL', 'ARMHF', 'AARCH64'):
            state.regs.lr = ret_bvv
        elif self.project.arch.name in ('MIPS32', 'MIPS64'):
            state.regs.ra = ret_bvv
        elif self.project.arch.name in ('PPC32', 'PPC64'):
            state.regs.lr = ret_bvv
        else:
            l.warning('Return address cannot be set for architecture %s. Please add corresponding logic to '
                      'VFG._set_return_address().', self.project.arch.name
                      )

    def _create_graph(self, return_target_sources=None):
        """
        Create a DiGraph out of the existing edge map.
        :param return_target_sources: Used for making up those missing returns
        :returns: A networkx.DiGraph() object
        """
        if return_target_sources is None:
            # We set it to a defaultdict in order to be consistent with the
            # actual parameter.
            return_target_sources = defaultdict(list)

        cfg = networkx.DiGraph()
        # The corner case: add a node to the graph if there is only one block
        if len(self._nodes) == 1:
            cfg.add_node(self._nodes[self._nodes.keys()[0]])

        # Adding edges
        for tpl, targets in self._exit_targets.items():
            basic_block = self._nodes[tpl] # Cannot fail :)
            for ex, jumpkind in targets:
                if ex in self._nodes:
                    target_bbl = self._nodes[ex]
                    cfg.add_edge(basic_block, target_bbl, jumpkind=jumpkind)

                    # Add edges for possibly missing returns
                    if basic_block.addr in return_target_sources:
                        for src_irsb_key in \
                                return_target_sources[basic_block.addr]:
                            cfg.add_edge(self._nodes[src_irsb_key],
                                               basic_block, jumpkind="Ijk_Ret")
                else:
                    # Debugging output
                    def addr_formalize(addr):
                        if addr is None:
                            return "None"
                        else:
                            return "%#08x" % addr

                    s = "(["
                    for addr in ex[:-1]:
                        s += addr_formalize(addr) + ", "
                    s += "] %s)" % addr_formalize(ex[-1])
                    l.warning("Key %s does not exist.", s)

        return cfg

    #
    # DiGraph manipulation
    #

    def _graph_get_node(self, node_key, terminator_for_nonexistent_node=False):
        """
        Get an existing VFGNode instance from the graph.

        :param SimRunKey node_key: The SimRun key for the node to get.
        :param bool terminator_for_nonexistent_node: True if a Terminator (which is a SimProcedure stub) should be
                                                     created when there is no existing node available for the given
                                                     SimRun key.
        :return: A node in the graph, or None.
        :rtype: VFGNode
        """

        if node_key not in self._nodes:
            l.error("Trying to look up a node that we don't have yet. is this okay????")
            if not terminator_for_nonexistent_node:
                return None
            # Generate a PathTerminator node
            addr = node_key.addr
            func_addr = node_key.func_addr
            if func_addr is None:
                # We'll have to use the current SimRun address instead
                # TODO: Is it really OK?
                func_addr = addr

            input_state = self.project.factory.entry_state()
            input_state.ip = addr
            pt = VFGNode(addr, node_key, input_state)
            self._nodes[node_key] = pt

            if isinstance(self.project.arch, archinfo.ArchARM) and addr % 2 == 1:
                self._thumb_addrs.add(addr)
                self._thumb_addrs.add(addr - 1)

            l.debug("SimRun key %s does not exist. Create a PathTerminator instead.",
                    repr(node_key))

        return self._nodes[node_key]

    def _graph_add_edge(self, src_node_key, dst_node_key, **kwargs):
        """
        Add an edge onto the graph.

        :param SimRunKey src_node_key: The SimRun key for source node.
        :param SimRunKey dst_node_key: The SimRun key for destination node.
        :param str jumpkind: The jumpkind of the edge.
        :param exit_stmt_idx: ID of the statement in the source IRSB where this edge is created from. 'default' refers
                              to the default exit.
        :return: None
        """

        dst_node = self._graph_get_node(dst_node_key, terminator_for_nonexistent_node=True)

        if src_node_key is None:
            self.graph.add_node(dst_node)

        else:
            src_node = self._graph_get_node(src_node_key, terminator_for_nonexistent_node=True)
            self.graph.add_edge(src_node, dst_node, **kwargs)

    #
    # Other methods
    #

    def _get_simrun(self, state, current_path, addr):
        error_occured = False
        restart_analysis = False

        jumpkind = 'Ijk_Boring'
        if current_path.state.scratch.jumpkind:
            jumpkind = current_path.state.scratch.jumpkind

        try:
            node = self._cfg.get_any_node(current_path.addr)
            num_inst = None if node is None else len(node.instruction_addrs)
            sim_run = self.project.factory.sim_run(current_path.state, jumpkind=jumpkind, num_inst=num_inst)
        except simuvex.SimIRSBError as ex:
            # It's a tragedy that we came across some instructions that VEX
            # does not support. I'll create a terminating stub there
            l.error("SimIRSBError occurred(%s). Creating a PathTerminator.", ex)
            error_occured = True
            sim_run = \
                simuvex.procedures.SimProcedures["stubs"]["PathTerminator"](
                    state, addr=addr)
        except claripy.ClaripyError as ex:
            l.error("ClaripyError: ", exc_info=True)
            error_occured = True
            # Generate a PathTerminator to terminate the current path
            sim_run = \
                simuvex.procedures.SimProcedures["stubs"]["PathTerminator"](
                    state, addr=addr)
        except simuvex.SimError as ex:
            l.error("SimError: ", exc_info=True)

            error_occured = True
            # Generate a PathTerminator to terminate the current path
            sim_run = \
                simuvex.procedures.SimProcedures["stubs"]["PathTerminator"](
                    state, addr=addr)
        except AngrError as ex:
            #segment = self.project.loader.main_bin.in_which_segment(addr)
            l.error("AngrError %s when creating SimRun at %#x",
                    ex, addr)
            # We might be on a wrong branch, and is likely to encounter the
            # "No bytes in memory xxx" exception
            # Just ignore it
            error_occured = True
            sim_run = None

        return sim_run, error_occured, restart_analysis

    def _create_new_jobs(self, job, successor, new_simrun_key, new_call_stack):
        """
        Create a list of new VFG jobs for the successor state.

        :param VFGJob job: The VFGJob instance.
        :param simuvex.SimState successor: THe succeeding state.
        :param SimRunKey new_simrun_key: SimRunKey for the new VFGJob
        :param new_call_stack: The new callstack.
        :return: A list of newly created VFG jobs.
        :rtype: list
        """

        # TODO: basic block stack is probably useless

        jumpkind = successor.scratch.jumpkind
        # Make a copy of the state in case we use it later
        successor_state = successor.copy()

        new_jobs = [ ]

        if jumpkind == "Ijk_FakeRet":
            assert job.is_call_jump

            # This is the default "fake" return successor generated at each call, if and only if the target function
            # returns.

            # if the call is skipped (for whatever reason, like we reached the interfunction tracing limit), we use
            # this FakeRet successor as the final state of the function. Otherwise we save the FakeRet state in case the
            # callee does not return normally, but don't process them right away.

            # Clear the useless values (like return addresses, parameters) on stack if needed
            if self._cfg is not None:
                current_function = self.kb.functions.function(job.call_target)
                if current_function is not None:
                    sp_difference = current_function.sp_delta
                else:
                    sp_difference = 0
                reg_sp_offset = successor_state.arch.sp_offset
                reg_sp_expr = successor_state.registers.load(reg_sp_offset) + sp_difference
                successor_state.registers.store(successor_state.arch.sp_offset, reg_sp_expr)

                # Clear the return value with a TOP
                top_si = successor_state.se.TSI(successor_state.arch.bits)
                successor_state.registers.store(successor_state.arch.ret_offset, top_si)

            if job.call_skipped:
                successor_path = self.project.factory.path(successor_state)
                new_job = VFGJob(successor_path.addr,
                                 successor_path,
                                 self._context_sensitivity_level,
                                 simrun_key=new_simrun_key,
                                 jumpkind='Ijk_Ret',
                                 call_stack=new_call_stack,
                                 )

                # create the function analysis task, since it should be created when we trace the callee, but we
                # skipped it
                task = FunctionAnalysis(successor_path.addr, None)
                self._task_stack.append(task)
                # Register the job to the call analysis task
                job.call_task.register_function_analysis(task)
                job.call_task.add_final_job(new_job)

                self._save_function_final_state(job.call_function_key, job.call_target, successor_state)

                job.dbg_exit_status[successor] = "Added as a final job"

            else:
                self._pending_returns[new_simrun_key] = \
                    (successor_state, new_call_stack)
                job.dbg_exit_status[successor] = "Pending"

        else:
            successor_path = self.project.factory.path(successor_state)
            if simuvex.o.ABSTRACT_MEMORY in successor.options:
                if self._is_call_jumpkind(successor.scratch.jumpkind):
                    # If this is a call, we create a new stack address mapping
                    reg_sp_si = self._create_stack_region(successor_path.state, successor_path.addr)

                    # Save the new sp register
                    new_reg_sp_expr = successor_path.state.se.ValueSet(successor_state.arch.bits,
                                                                       'global',
                                                                       0,
                                                                       reg_sp_si
                                                                       )
                    successor_path.state.regs.sp = new_reg_sp_expr

                elif successor.scratch.jumpkind == "Ijk_Ret":
                    # Remove the existing stack address mapping
                    # FIXME: Now we are assuming the sp is restored to its original value
                    reg_sp_expr = successor_path.state.regs.sp

                    if isinstance(reg_sp_expr._model_vsa, claripy.vsa.StridedInterval):
                        reg_sp_si = reg_sp_expr._model_vsa
                        reg_sp_val = reg_sp_si.min
                    elif isinstance(reg_sp_expr._model_vsa, claripy.vsa.ValueSet):
                        reg_sp_si = reg_sp_expr._model_vsa.items()[0][1]
                        reg_sp_val = reg_sp_si.min
                        # TODO: Finish it!

            new_job = VFGJob(successor_path.addr,
                             successor_path,
                             self._context_sensitivity_level,
                             simrun_key=new_simrun_key,
                             jumpkind=successor_path.state.scratch.jumpkind,
                             call_stack=new_call_stack,
                             )
            # r = self._worklist_append_entry(new_exit_wrapper)
            # _dbg_exit_status[successor] = r

            if successor.scratch.jumpkind == 'Ijk_Ret':
                # it's returning to the return site

                # save the state as a final state of the function that we are returning from
                source_function_key = FunctionKey.new(job.func_addr, job.call_stack_suffix) # key of the function that we are returning from
                self._save_function_final_state(source_function_key, job.func_addr, successor_state)

                # TODO: add an assertion that requires the returning target being the same as the return address we
                # TODO: stored before

                current_task = self._top_task
                if current_task.call_analysis is not None:
                    current_task.call_analysis.add_final_job(new_job)

                    job.dbg_exit_status[successor] = "Appended to the call analysis task"
                else:
                    job.dbg_exit_status[successor] = "Discarded (no call analysis task)"

            else:
                if self._is_call_jumpkind(successor.scratch.jumpkind):
                    # create a function analysis task
                    # TODO: the return address
                    task = FunctionAnalysis(new_job.addr, None)
                    self._task_stack.append(task)
                    # link it to the call analysis
                    job.call_task.register_function_analysis(task)

                else:
                    task = self._top_task

                # register the job to the function task
                task.jobs.append(new_job)
                # insert the new job into the new job array
                new_jobs.append(new_job)

                job.dbg_exit_status[successor] = "Appended"

        if not job.is_call_jump or jumpkind != "Ijk_FakeRet":
            new_target = (new_simrun_key, jumpkind)
        else:
            new_target = (new_simrun_key, "Ijk_FakeRet")  # This is the fake return!
        self._exit_targets[job.call_stack_suffix + (job.path.addr,)].append(new_target)

        return new_jobs

    def _remove_pending_return(self, entry_wrapper, pending_returns):
        """
        Remove all pending returns that are related to the current entry.
        """

        # Build the tuples that we want to remove from the dict fake_func_retn_exits
        tpls_to_remove = [ ]
        call_stack_copy = entry_wrapper.call_stack_copy()
        while call_stack_copy.current_return_target is not None:
            ret_target = call_stack_copy.current_return_target
            # Remove the current call stack frame
            call_stack_copy.ret(ret_target)
            call_stack_suffix = call_stack_copy.stack_suffix(self._context_sensitivity_level)
            tpl = call_stack_suffix + (ret_target,)
            tpls_to_remove.append(tpl)

        # Remove those tuples from the dict
        for tpl in tpls_to_remove:
            if tpl in pending_returns:
                del pending_returns[tpl]
                l.debug("Removed (%s) from FakeExits dict.",
                        ",".join([hex(i) if i is not None else 'None' for i in tpl]))

    def _post_entry_handling_dbg(self, job, successors):
        """
        Print out debugging information after handling a VFGJob and generating the succeeding jobs.

        :param VFGJob job: The VFGJob instance.
        :param list successors: A list of succeeding states.
        :return: None
        """

        function_name = self.project.loader.find_symbol_name(job.addr)
        module_name = self.project.loader.find_module_name(job.addr)

        l.debug("VFGJob @ %#08x with callstack %s", job.addr,
                "->".join([hex(i) for i in job.call_stack_suffix if i is not None])
                )
        l.debug("(Function %s of %s)", function_name, module_name)
        l.debug("-  is call jump: %s", job.is_call_jump)
        for suc in successors:
            if suc not in job.dbg_exit_status:
                # TODO:
                l.warning("- %s is not found. FIND OUT WHY.", suc)
                continue

            try:
                l.debug("-  successor: %#08x of %s [%s]", suc.se.exactly_int(suc.ip),
                        suc.scratch.jumpkind, job.dbg_exit_status[suc])
            except simuvex.SimValueError:
                l.debug("-  target cannot be concretized. %s [%s]", job.dbg_exit_status[suc], suc.scratch.jumpkind)
        l.debug("Remaining/pending jobs: %d/%d", len(self._entries), len(self._pending_returns))

    @staticmethod
    def _is_call_jumpkind(jumpkind):
        if jumpkind == 'Ijk_Call' or jumpkind.startswith('Ijk_Sys_'):
            return True
        return False

    @staticmethod
    def _create_stack_region(successor_state, successor_ip):
        reg_sp_offset = successor_state.arch.sp_offset
        reg_sp_expr = successor_state.registers.load(reg_sp_offset)

        if type(reg_sp_expr._model_vsa) is claripy.BVV:  # pylint:disable=unidiomatic-typecheck
            reg_sp_val = successor_state.se.any_int(reg_sp_expr)
            reg_sp_si = successor_state.se.SI(to_conv=reg_sp_expr)
            reg_sp_si = reg_sp_si._model_vsa
        elif type(reg_sp_expr._model_vsa) in (int, long):  # pylint:disable=unidiomatic-typecheck
            reg_sp_val = reg_sp_expr._model_vsa
            reg_sp_si = successor_state.se.SI(bits=successor_state.arch.bits, to_conv=reg_sp_val)
            reg_sp_si = reg_sp_si._model_vsa
        elif type(reg_sp_expr._model_vsa) is claripy.vsa.StridedInterval:  # pylint:disable=unidiomatic-typecheck
            reg_sp_si = reg_sp_expr._model_vsa
            reg_sp_val = reg_sp_si.min
        else:
            reg_sp_si = reg_sp_expr._model_vsa.items()[0][1]
            reg_sp_val = reg_sp_si.min

        reg_sp_val = reg_sp_val - successor_state.arch.bytes  # TODO: Is it OK?
        new_stack_region_id = successor_state.memory.stack_id(successor_ip)
        successor_state.memory.set_stack_address_mapping(reg_sp_val,
                                                        new_stack_region_id,
                                                        successor_ip)

        return reg_sp_si

    def _create_callstack(self, entry_wrapper, successor_ip, jumpkind, is_call_jump, fakeret_successor):
        addr = entry_wrapper.path.addr

        if self._is_call_jumpkind(jumpkind):
            if len(entry_wrapper.call_stack) <= self._interfunction_level:
                new_call_stack = entry_wrapper.call_stack_copy()
                # Notice that in ARM, there are some freaking instructions
                # like
                # BLEQ <address>
                # It should give us three exits: Ijk_Call, Ijk_Boring, and
                # Ijk_Ret. The last exit is simulated.
                # Notice: We assume the last exit is the simulated one
                if fakeret_successor is None:
                    retn_target_addr = None
                else:
                    retn_target_addr = fakeret_successor.se.exactly_n_int(fakeret_successor.ip, 1)[0]

                # Create call stack
                new_call_stack.call(addr, successor_ip,
                                    retn_target=retn_target_addr)
            else:
                return None

        elif jumpkind == "Ijk_Ret" and not is_call_jump:
            new_call_stack = entry_wrapper.call_stack_copy()
            new_call_stack.ret(successor_ip)

        else:
            # Normal control flow transition
            new_call_stack = entry_wrapper.call_stack

        return new_call_stack

    def _save_function_initial_state(self, function_key, function_address, state):
        """
        Save the initial state of a function, and merge it with existing ones if there are any.

        :param FunctionKey function_key: The key to this function.
        :param int function_address: Address of the function.
        :param simuvex.SimState state: Initial state of the function.
        :return: None
        """

        l.debug('Saving the initial state for function %#08x with function key %s',
                function_address,
                function_key
                )
        if function_key in self._function_initial_states[function_address]:
            existing_state = self._function_initial_states[function_address][function_key]
            merged_state, _, _ = existing_state.merge(state)
            self._function_initial_states[function_address][function_key] = merged_state

        else:
            self._function_initial_states[function_address][function_key] = state

    def _save_function_final_state(self, function_key, function_address, state):
        """
        Save the final state of a function, and merge it with existing ones if there are any.

        :param FunctionKey function_key: The key to this function.
        :param int function_address: Address of the function.
        :param simuvex.SimState state: Initial state of the function.
        :return: None
        """

        l.debug('Saving the final state for function %#08x with function key %s',
                function_address,
                function_key
                )

        if function_key in self._function_final_states[function_address]:
            existing_state = self._function_final_states[function_address][function_key]
            merged_state = existing_state.merge(state)[0]
            self._function_final_states[function_address][function_key] = merged_state

        else:
            self._function_final_states[function_address][function_key] = state

    def _get_block_addr(self, b): #pylint:disable=R0201
        if isinstance(b, simuvex.SimIRSB):
            return b.first_imark.addr
        elif isinstance(b, simuvex.SimProcedure):
            return b.addr
        else:
            raise Exception("Unsupported block type %s" % type(b))

    def _get_nx_paths(self, begin, end):
        """
        Get the possible (networkx) simple paths between two nodes or addresses
        corresponding to nodes.
        Input: addresses or node instances
        Return: a list of lists of nodes representing paths.
        """
        if type(begin) in (int, long) and type(end) in (int, long):  # pylint:disable=unidiomatic-typecheck
            n_begin = self.get_any_node(begin)
            n_end = self.get_any_node(end)

        elif isinstance(begin, VFGNode) and isinstance(end, VFGNode):  # pylint:disable=unidiomatic-typecheck
            n_begin = begin
            n_end = end
        else:
            raise AngrVFGError("from and to should be of the same type")

        return networkx.all_simple_paths(self.graph, n_begin, n_end)

    def _merge_points(self, function_address):
        """
        Return the ordered merge points for a specific function.

        :param int function_address: Address of the querying function.
        :return: A list of sorted merge points (addresses).
        :rtype: list
        """

        # we are entering a new function. now it's time to figure out how to optimally traverse the control flow
        # graph by generating the sorted merge points
        new_function = self.kb.functions[function_address]

        if function_address not in self._function_merge_points:
            ordered_merge_points = CFGUtils.find_merge_points(function_address, new_function.endpoints,
                                                           new_function.graph)
            self._function_merge_points[function_address] = ordered_merge_points

        return self._function_merge_points[function_address]

register_analysis(VFG, 'VFG')
