name: Test with coverage

on:
  push:
    branches:
      - master
  pull_request:
  workflow_dispatch:

env:
  SKIP_SLOW_TESTS: 1
  RUSTFLAGS: "-C instrument-coverage -C codegen-units=1 -C link-dead-code"
  LLVM_PROFILE_FILE: "%p-%m.profraw"
  CFLAGS: "--coverage -O0 -g"
  LDFLAGS: "--coverage -g"

jobs:
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v4
      - uses: Swatinem/rust-cache@f13886b937689c021905a6b90929199931d60db1 # v2
      - uses: astral-sh/setup-uv@2ddd2b9cb38ad8efd50337e8ab201519a34c9f24 # v6
        with:
          python-version: "3.10"
      - name: Restore test durations cache
        uses: actions/cache/restore@v4
        with:
          path: test_durations.json
          key: cov-test-durations-${{ github.sha }}
          restore-keys: cov-test-durations-
      - name: Build
        run: uv sync -v -p 3.10 --all-groups
      - name: Archive environment
        run: tar -cpf /tmp/env.tzst --absolute-names --zstd $PWD $UV_CACHE_DIR $UV_PYTHON_INSTALL_DIR
      - name: Upload environment artifact
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: env
          path: /tmp/env.tzst
          if-no-files-found: error
          compression-level: 0

  test:
    needs: [build]
    name: Test
    runs-on: ubuntu-latest
    strategy:
      matrix:
        runner_id: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
    steps:
      - uses: actions/download-artifact@018cc2cf5baa6db3ef3c5f8a56943fffe632ef53 # v6.0.0
        with:
          name: env
          path: .
      - name: Extract environment
        run: |
          tar -xpf $PWD/env.tzst -C /
          rm env.tzst
      - name: Download test binaries
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v4
        with:
          repository: angr/binaries
          path: binaries
      - name: Relocate binaries directory
        run: mv binaries ..
      - name: Run tests
        run: |
          source .venv/bin/activate
          pytest -vv \
            -n auto --splits 10 --group ${{ matrix.runner_id }} --splitting-algorithm=least_duration \
            --cov=angr --cov=tests --cov-report=xml \
            --junitxml=junit.xml -o junit_family=legacy \
            --store-durations --clean-durations --durations-path=test_durations.json \
            || [[ $? -lt 2 ]]  # Accept success and test failures, fail on infrastructure problems (exit codes >1)
          gcovr -r native --print-summary --xml-pretty -o coverage-native.xml
      - name: Check for results
        run: |
          [[ -e junit.xml && -e coverage.xml && -e coverage-native.xml && -e test_durations.json ]]
      - name: Upload results artifact
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: results-${{ matrix.runner_id }}
          if-no-files-found: error
          path: |
            ./junit.xml
            ./coverage.xml
            ./coverage-native.xml
            ./test_durations.json
            ./*.profraw

  test_rust:
    name: Test Rust packages
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v4
      - uses: Swatinem/rust-cache@f13886b937689c021905a6b90929199931d60db1 # v2
      - uses: actions-rust-lang/setup-rust-toolchain@1780873c7b576612439a134613cc4cc74ce5538c # v1
      - uses: taiki-e/install-action@e43a5023a747770bfcb71ae048541a681714b951 # v2
        with:
          tool: cargo-llvm-cov
      - uses: actions/setup-python@e797f83bcb11b83ae66e0230d6156d7c80228e7c # v5
        with:
          python-version: "3.10"
      - name: Run tests
        run: |
          cargo test --release
          cargo llvm-cov --lcov --output-path lcov.info
      - name: Upload results artifact
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: results-rust
          if-no-files-found: error
          path: lcov.info

  report:
      name: Report
      runs-on: ubuntu-latest
      permissions:
        id-token: write
        checks: write
      needs: [test, test_rust]
      steps:
      - name: Download environment
        uses: actions/download-artifact@018cc2cf5baa6db3ef3c5f8a56943fffe632ef53 # v6.0.0
        with:
          name: env
          path: .
      - name: Extract environment
        run: |
          tar -xpf $PWD/env.tzst -C /
          rm env.tzst
      - name: Download results
        uses: actions/download-artifact@018cc2cf5baa6db3ef3c5f8a56943fffe632ef53 # v6.0.0
        with:
          pattern: "results-*"
          path: results
      - name: Combine Rust coverage
        run: |
          find results

          # XXX: Workaround slow `Processing triggers for man-db...`
          echo 'set man-db/auto-update false' | sudo debconf-communicate
          sudo dpkg-reconfigure man-db

          sudo apt-get install -qq llvm-20 llvm-20-tools
          echo "Merging coverage..."
          llvm-profdata-20 merge -sparse $(find . -name '*.profraw') -o default.profdata
          echo "Generating report..."
          llvm-cov-20 report ./angr/rustylib*.so -instr-profile=default.profdata --sources $(find native -name "*.rs")
          llvm-cov-20 export ./angr/rustylib*.so -instr-profile=default.profdata --sources $(find native -name "*.rs") --format=lcov > lcov-py.info
      - name: Collect results
        id: files
        run: |
          coverage=$(find . -type f \( -name 'coverage*.xml' -o -name 'lcov*.info' \) | paste -sd, -)
          echo "coverage=$coverage" >> "$GITHUB_OUTPUT"
          junit=$(find . -type f -name 'junit.xml' | paste -sd, -)
          echo "junit=$junit" >> "$GITHUB_OUTPUT"
      - name: Upload test coverage to Codecov
        uses: codecov/codecov-action@5a1091511ad55cbe89839c7260b706298ca349f7 # v5
        with:
          use_oidc: true
          fail_ci_if_error: true
          verbose: true
          files: ${{ steps.files.outputs.coverage }}
      - name: Upload test results to Codecov
        uses: codecov/test-results-action@47f89e9acb64b76debcd5ea40642d25a4adced9f # v1
        with:
          use_oidc: true
          fail_ci_if_error: true
          verbose: true
          files: ${{ steps.files.outputs.junit }}
      - name: Combine test durations
        run: jq -Ss 'add' results/**/test_durations.json > test_durations.json
      - name: Upload combined test durations artifact
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: test_durations
          path: ./test_durations.json
          if-no-files-found: error
      - name: Update test durations cache
        uses: actions/cache/save@v4
        with:
          path: test_durations.json
          key: cov-test-durations-${{ github.sha }}
      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@3a74b2957438d0b6e2e61d67b05318aa25c9e6c6 # v2
        with:
          files: "results/**/junit.xml"
          action_fail_on_inconclusive: true
          comment_mode: off  # codecov already leaves a comment, and more details
                             # from this action can be found in the check it creates.